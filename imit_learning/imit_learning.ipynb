{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem Statement:\n",
    "# Pick a double integrator. Implement a PD controller for it.\n",
    "# Use imitation learning (Dagger) to learn the PD controller.\n",
    "# Use RL to improve on the imitation learning when there are disturbances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "font = {'family' : 'serif',\n",
    "        'serif' : 'Computer Modern Roman',\n",
    "        'size'   : 16}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['figure.figsize'] = [2*3.54, 3.54]\n",
    "\n",
    "from systems import DoubleIntegrator, DoubleIntegratorWithPerturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "N = 300\n",
    "\n",
    "# Systems\n",
    "system = DoubleIntegrator(dt)\n",
    "system_perturbed = DoubleIntegratorWithPerturbations(dt)\n",
    "\n",
    "system.state = np.zeros(2)\n",
    "system_perturbed.state = np.zeros(2)\n",
    "state_list = []\n",
    "state_perturb_list = []\n",
    "\n",
    "for i in range(N):\n",
    "    action = np.array([0.1])\n",
    "    result = system.step(action)\n",
    "    result_perturb = system_perturbed.step(action)\n",
    "    state_list.append(system.state)\n",
    "    state_perturb_list.append(system_perturbed.state)\n",
    "    \n",
    "fig, ax = plt.subplots(2, 1, figsize=(4, 4), sharex=True)\n",
    "state_list = np.array(state_list)\n",
    "state_perturb_list = np.array(state_perturb_list)\n",
    "# ax[0].plot(state_list[:, 0], '-', label='x')\n",
    "ax[0].plot(state_perturb_list[:, 0], '--', label='x with perturbations')\n",
    "# ax[1].plot(state_list[:, 1], '-', label='\\dot{x}')    \n",
    "ax[1].plot(state_perturb_list[:, 1], '--', label='\\dot{x} with perturbations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expert Policies\n",
    "class ExpertPolicyIntegral:\n",
    "    def __init__(self, dt):\n",
    "        self.integral_term = 0\n",
    "        self.dt = dt\n",
    "        self.K = np.array([40.0 , 30.0]).reshape(1, 2)\n",
    "        self.K_I = 10.0\n",
    "        \n",
    "    def __call__(self, state, state_des):\n",
    "        self.integral_term += - self.K_I * (state[0] - state_des[0]) * self.dt\n",
    "        # TODO antiwindup \n",
    "        u = (-self.K @ (state - state_des))  + self.integral_term\n",
    "        return u\n",
    "    \n",
    "class ExpertPolicyPD:\n",
    "    def __init__(self, dt):\n",
    "        self.dt = dt\n",
    "        self.K = np.array([40.0 , 30.0]).reshape(1, 2)\n",
    "        \n",
    "    def __call__(self, state, state_des):\n",
    "        u = (-self.K @ (state - state_des))\n",
    "        return u\n",
    "\n",
    "class ExpertPolicyNonlinearPD:\n",
    "    def __init__(self, dt):\n",
    "        self.dt = dt\n",
    "        self.K = np.array([40.0 , 30.0]).reshape(1, 2)\n",
    "        \n",
    "    def __call__(self, state, state_des):\n",
    "        u = (-self.K @ (state - state_des)) + (10*np.sin(state[0]/10))**2\n",
    "        return u\n",
    "        \n",
    "expert_policy = ExpertPolicyPD(dt)\n",
    "expert_policy_nonlinear = ExpertPolicyNonlinearPD(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the expert controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desired_trajectory(N, dt):\n",
    "    '''\n",
    "    Args: \n",
    "        N : int - length of the trajectory\n",
    "        dt : float - time step\n",
    "    Returns:\n",
    "        x_vec_d [x_d, x_dot_d] : np.array (N x 2) - desired trajectory\n",
    "    '''\n",
    "    frequency = np.random.uniform(0.01, 0.05)\n",
    "    print('Frequency', frequency)\n",
    "    x_d_fcn = lambda t: np.cos(t*frequency)\n",
    "    x_d = [x_d_fcn(i) for i in range(N)]\n",
    "    x_dot_d = np.zeros(N)\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x_dot_d[i] = (x_d[i+1] - x_d[i])/dt\n",
    "    x_dot_d[-1] = x_dot_d[-2]\n",
    "\n",
    "    x_vec_d = np.array([x_d, x_dot_d]).T\n",
    "    return x_vec_d\n",
    "\n",
    "\n",
    "x_vec_d = desired_trajectory(N, dt)\n",
    "system_perturbed.state = np.array([x_vec_d[0, 0], x_vec_d[0, 1]])\n",
    "state_list = []\n",
    "\n",
    "\n",
    "des_traj_list = []\n",
    "x0 = np.array([x_vec_d[0, 0], x_vec_d[0, 1]])\n",
    "system_perturbed.state = x0.copy()\n",
    "\n",
    "for i in range(N-1):\n",
    "    state_des = np.array([ x_vec_d[i, 0], x_vec_d[i, 1] ])\n",
    "    action = expert_policy(system_perturbed.state, state_des)\n",
    "    result = system_perturbed.step(action)\n",
    "    next_state = result[0]\n",
    "    state_list.append(system_perturbed.state)\n",
    "    des_traj_list.append(state_des)\n",
    "    \n",
    "state_list = np.array(state_list)\n",
    "des_traj_list = np.array(des_traj_list)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(2, 2), sharex=True)\n",
    "ax[0].set_title('Tracking Performance')\n",
    "ax[0].plot(state_list[:, 0], '-', label='x')\n",
    "ax[0].plot(des_traj_list[:, 0], '--', label='x_d')\n",
    "ax[0].legend(fontsize='xx-small')\n",
    "\n",
    "ax[1].plot(state_list[:, 1], '-', label='\\dot{x}')\n",
    "ax[1].plot(des_traj_list[:, 1], '--', label='\\dot{x}_d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Multiple traj regulation:\n",
    "def multiple_traj_reg(sys, sys_name, policy):\n",
    "    nb_traj = 1\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(2, 2), sharex=True)\n",
    "    for i in range(nb_traj):\n",
    "        sys.reset()\n",
    "        state_list = []\n",
    "        x_vec_d = desired_trajectory(N, dt)\n",
    "        sys.state = np.array([x_vec_d[0, 0], x_vec_d[0, 1]])\n",
    "\n",
    "        for i in range(N):\n",
    "            state_des = np.array([ x_vec_d[i, 0], x_vec_d[i, 1] ])\n",
    "            action = policy(sys.state, state_des)\n",
    "            if type(action) is not np.ndarray:\n",
    "                action = action.detach().numpy()\n",
    "            result = sys.step(action)\n",
    "            state_list.append(sys.state)\n",
    "            \n",
    "        state_list = np.array(state_list)\n",
    "        ax[0].plot(state_list[:, 0], '-', label='x')\n",
    "        ax[0].plot(x_vec_d[:, 0], '--', label='x_d')\n",
    "        ax[1].plot(state_list[:, 1], '-', label='\\dot{x}')    \n",
    "        ax[1].plot(x_vec_d[:, 1], '--', label='\\dot{x}_d')\n",
    "        ax[0].set_title(sys_name, fontsize='xx-small')\n",
    "\n",
    "multiple_traj_reg(system, sys_name = 'Double Integrator', policy=expert_policy)\n",
    "multiple_traj_reg(system_perturbed, sys_name = 'Double Integrator with Perturbations', policy=expert_policy)\n",
    "multiple_traj_reg(system_perturbed, sys_name = 'Double Integrator with Perturbations', policy=expert_policy_nonlinear)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Dagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnpolicy import NNPolicy\n",
    "from DAgger import DAgger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "net_arch = [(input_size, 24), (24, 48), (48, 24), (24, 1)] # NN policy\n",
    "policy = NNPolicy(net_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "\n",
    "dagger_trainer = DAgger(system, expert_policy, policy, desired_trajectory, np.linspace(1, 0, epochs), 300, None, 1, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dagger_trainer.train_dagger(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "\n",
    "def policy_NN(x, x_des):\n",
    "    input_NN = np.concatenate([x, x_des])\n",
    "    return policy.predict(input_NN)\n",
    "\n",
    "multiple_traj_reg(system, sys_name = 'Double Integrator', policy=policy_NN)\n",
    "multiple_traj_reg(system_perturbed, sys_name = 'Double Integrator with Perturbations; Policy Dagger', policy=policy_NN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_traj_reg(system_perturbed, sys_name = 'Double Integrator with Perturbations; Policy Dagger', policy=policy_NN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
