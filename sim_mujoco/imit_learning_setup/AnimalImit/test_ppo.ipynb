{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the PPO Algorithm\n",
    "## (gym env, no imitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import pybullet_envs\n",
    "\n",
    "import torch\n",
    "from ppo import Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the policy setup is here. Needs to match the parameters used to train the model originally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_name = \"ppo_policy_6\"\n",
    "\n",
    "def make_env(gym_id, seed, idx, capture_video, run_name):\n",
    "    def thunk():\n",
    "        env = gym.make(gym_id)\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        if capture_video:\n",
    "            if idx == 0:\n",
    "                env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
    "        env = gym.wrappers.ClipAction(env)\n",
    "        env = gym.wrappers.NormalizeObservation(env)\n",
    "        env = gym.wrappers.TransformObservation(env, lambda obs: np.clip(obs, -10, 10))\n",
    "        env = gym.wrappers.NormalizeReward(env)\n",
    "        env = gym.wrappers.TransformReward(env, lambda reward: np.clip(reward, -10, 10))\n",
    "        env.seed(seed)\n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "        return env\n",
    "\n",
    "    return thunk\n",
    "\n",
    "\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [make_env(\"HalfCheetahBulletEnv-v0\", 1 + i, i, True, policy_name) for i in range(1)]\n",
    ")\n",
    "policy_arch = [\n",
    "    {'Layer': 'Linear', 'Input': np.array(envs.single_observation_space.shape).prod(), 'Output': 64, 'std': np.sqrt(2)},\n",
    "    {'Layer': 'Tanh'},\n",
    "    {'Layer': 'Linear', 'Input': 64, 'Output': 64, 'std': np.sqrt(2)},\n",
    "    {'Layer': 'Tanh'},\n",
    "    {'Layer': 'Linear', 'Input': 64, 'Output': np.array(envs.single_action_space.shape).prod(), 'std': 0.01},\n",
    "]\n",
    "value_arch = [\n",
    "    {'Layer': 'Linear', 'Input': np.array(envs.single_observation_space.shape).prod(), 'Output': 64, 'std': np.sqrt(2)},\n",
    "    {'Layer': 'Tanh'},\n",
    "    {'Layer': 'Linear', 'Input': 64, 'Output': 64, 'std': np.sqrt(2)},\n",
    "    {'Layer': 'Tanh'},\n",
    "    {'Layer': 'Linear', 'Input': 64, 'Output': 1, 'std': 1.0},\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the agent, set it to `eval_mode = True` so that actions are deterministic, and evaluate on the half-cheeta environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run vanilla behavior cloning\n",
    "agent = Agent(envs, policy_arch, value_arch)\n",
    "agent.load_policy(f\"policies/{policy_name}.pt\")\n",
    "agent.set_eval_mode(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now do some plotting to examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = envs.reset()\n",
    "done = np.array([False, False])\n",
    "with torch.no_grad():\n",
    "    while not done.any():\n",
    "        u = agent.get_action_and_value(torch.Tensor(obs))\n",
    "        res = envs.step(u.cpu().numpy())\n",
    "        obs = res[0]\n",
    "        done = res[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imit_biped",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
