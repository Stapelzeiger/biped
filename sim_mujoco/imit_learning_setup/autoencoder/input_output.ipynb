{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# custom autoencoder\n",
    "from autoencoder import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "DATA_REL_PATHS = [\n",
    "    # \"../../sim_mujoco/data/dataset_backwards.csv\", \"../../sim_mujoco/data/dataset_forward_sideways.csv\", \"../../sim_mujoco/data/dataset_misc.csv\"\n",
    "    # \"../../sim_mujoco/data/in_place_long.csv\"\n",
    "    \"../../sim_mujoco/data/in_place.csv\"\n",
    "]\n",
    "UPDATED_DATA_NAME = \"in_place_v1.csv\"\n",
    "POLICY_NAME = \"autoencoder_output_states_v1\"\n",
    "TRAIN_FRAC = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "# autoencode input_states\n",
    "\n",
    "\n",
    "# autoencode output_states?\n",
    "# should be 30\n",
    "action_columns = [\n",
    "    \"L_YAW_tau_ff\", \"L_HAA_tau_ff\", \"L_HFE_tau_ff\", \"L_KFE_tau_ff\", \"L_ANKLE_tau_ff\",\n",
    "    \"R_YAW_tau_ff\", \"R_HAA_tau_ff\", \"R_HFE_tau_ff\", \"R_KFE_tau_ff\", \"R_ANKLE_tau_ff\",\n",
    "    \"L_YAW_q_des\", \"L_HAA_q_des\", \"L_HFE_q_des\", \"L_KFE_q_des\", \"L_ANKLE_q_des\",\n",
    "    \"R_YAW_q_des\", \"R_HAA_q_des\", \"R_HFE_q_des\", \"R_KFE_q_des\", \"R_ANKLE_q_des\",\n",
    "    \"L_YAW_q_vel_des\", \"L_HAA_q_vel_des\", \"L_HFE_q_vel_des\", \"L_KFE_q_vel_des\", \"L_ANKLE_q_vel_des\",\n",
    "    \"R_YAW_q_vel_des\", \"R_HAA_q_vel_des\", \"R_HFE_q_vel_des\", \"R_KFE_q_vel_des\", \"R_ANKLE_q_vel_des\"\n",
    "]\n",
    "\n",
    "OUTPUT_STATES = len(action_columns)\n",
    "LOSS_RATE = 0.001\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "dataset = pd.DataFrame()\n",
    "for dp in DATA_REL_PATHS:\n",
    "    ds = pd.read_csv(dp)\n",
    "    dataset = pd.concat((dataset, ds))\n",
    "num_steps = dataset.shape[0]\n",
    "actions = dataset[action_columns].to_numpy(dtype=np.float64)\n",
    "\n",
    "# grab the data excluded from training for fair test\n",
    "test_actions = actions[int(num_steps * TRAIN_FRAC):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of the Autoencoder\n",
    "autoencoder = Autoencoder(OUTPUT_STATES)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=LOSS_RATE)\n",
    "\n",
    "# TODO:\n",
    "# Training loop\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     # Forward pass\n",
    "#     outputs = autoencoder(inputs)\n",
    "#     loss = criterion(outputs, inputs)\n",
    "\n",
    "#     # Backward and optimize\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     # Print the loss for every 100 epochs\n",
    "#     if (epoch+1) % 100 == 0:\n",
    "#         print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
